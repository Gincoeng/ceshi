{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss\n",
      "aa\n",
      "(64, 64, 3)\n",
      "()\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_producer, input_producer/Const, ^input_producer/Assert/Assert)]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape () for Tensor 'Placeholder_1:0', which has shape '(?, 5)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-baf94a49c412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1074\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1076\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1077\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape () for Tensor 'Placeholder_1:0', which has shape '(?, 5)'"
     ]
    }
   ],
   "source": [
    "#导入各种库\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "#time_start = time.time()\n",
    "\n",
    "\n",
    "#定义读取TFRecords的函数\n",
    "def read_and_decode(filename):\n",
    "    filename_queue = tf.train.string_input_producer([filename])  #生成一个queue队列\n",
    "    reader = tf.TFRecordReader()\n",
    "    _,serialized_example = reader.read(filename_queue) #返回文件名和文件\n",
    "\n",
    "        #解析label和image信息，这个名字需要与生成TFRecord的时候一致\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'label':tf.FixedLenFeature([],tf.int64),\n",
    "                                           'img_raw':tf.FixedLenFeature([],tf.string)\n",
    "                                            }) #将image数据个label取出来\n",
    "    img = tf.decode_raw(features['img_raw'],tf.uint8)\n",
    "    img = tf.reshape(img,[64,64,3]) #reshape为64*64的3通道照片\n",
    "    label = tf.cast(features['label'],tf.int32) #tf.cast就是进行数据转换为int32，在数据流中抛出label张量\n",
    "    return img,label\n",
    "\n",
    "#定义精准度函数\n",
    "def compute_accuracy(v_xs,v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction,feed_dict={xs:v_xs,keep_prob:1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1),tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    result = sess.run(accuracy,feed_dict={xs:v_xs,ys:v_ys,keep_prob:1})\n",
    "    return result\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1) # shape表示生成张量的维度 stddev是标准差\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#定义卷积神经网络层了\n",
    "def conv2d(x,W):   # x代表输入的值，或者是图片的值。 W就是weight\n",
    "    #strides=[1,x轴移动距离，y轴移动距离，1]\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')#padding就是选择是否使用填充的扫描方式\n",
    "    #这里就是返回tensorflow中2维的卷积神经网络。 \n",
    "    \n",
    "    #第三个参数就是设置步长，在tensorflow中它是一个长度为4的列表。在这个列表中第一个以及最后一个元素都是必须等于1的。列表中间的两个\n",
    "    #参数分别是代表在x轴，y轴上移动的距离\n",
    "    \n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    #使用最大池化的方法， ksize=[1,height,width,1]这个是池化窗口的大小\n",
    "\n",
    "#设置placeholder来进行数据的传输\n",
    "xs = tf.placeholder(tf.float32,[64,64,3])\n",
    "ys = tf.placeholder(tf.float32,[None,5])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs,[-1,64,64,3]) #在定义卷积层之前，先要定义一下我们的输入。就是图片的输入\n",
    "                                      #-1表示不规定样本数量的多少，28×28是代表这个图片的尺寸，最后的1 是代表深度为1.\n",
    "      \n",
    "#第一层卷积层\n",
    "W_conv1 = weight_variable([5,5,3,32]) # 5*5就是patch的大小(就是卷积核的大小),1是代表输入通道数(如果是彩色图像就是3),32是代表有32个神经元就是有32个卷积核去关注32个特征 \n",
    "b_conv1 = bias_variable([32]) #有32个权值，那么所以就对应有32个偏置。\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1) #这一行就是卷积行    输出的大小是28*28*32,因为使用的padding是same，所以长宽不变\n",
    "h_pool1 = max_pool_2x2(h_conv1) #这一行的输出就是这一层卷积池化之后得到的结果   输出的大小是14*14*32,因为扫描的间距是2，所以缩小了一半\n",
    "\n",
    "#第二层卷积层\n",
    "W_conv2 = weight_variable([5,5,32,64]) #32是上一层的输出通道数，变成下一层的输入通道数。然后用64个卷积核去patch\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2) #输出的大小14*14*64\n",
    "h_pool2 = max_pool_2x2(h_conv2)                          #输出的大小7*7*64\n",
    "\n",
    "#全链接层1\n",
    "W_fc1 = weight_variable([16*16*64,1024]) #输入就是上一层的输出，使用包含1024个神经元的一层来处理整个图片\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,16*16*64])#把第二层卷积网络出来的 三维数据转换为一维数据\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)\n",
    "\n",
    "#全链接层2\n",
    "W_fc2 = weight_variable([1024,5]) #上一层的输出就是下一层的输入，最终是判断出0-9的图片\n",
    "b_fc2 = bias_variable([5])\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)  #最后一层的分类时使用的激活函数使用softmax\n",
    "# h_fc2_drop = tf.dropout(h_fc2,keep_prob)  #输出层可以不使用dropout\n",
    "\n",
    "\n",
    "#设置代价误差函数\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction),reduction_indices=[1]))\n",
    "# tf.summary.scalar('loss',cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)#不采用梯度下降的原因是：庞大的系统应该使用更好的优化器\n",
    "\n",
    "#全局变量的初始化\n",
    "init = tf.global_variables_initializer()\n",
    "batch = read_and_decode('fenlei_train.tfrecords')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"ss\")\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads =tf.train.start_queue_runners(coord=coord)\n",
    "    print(\"aa\")\n",
    "    for i in range(10):\n",
    "        img,label = sess.run(batch)\n",
    "        print(np.shape(img))\n",
    "        print(np.shape(label))\n",
    "        sess.run(train_step,feed_dict={xs:img,ys:label,keep_prob:0.5})\n",
    "        \n",
    "        if i % 2 == 0:\n",
    "            print('program is running 7')\n",
    "    #         print(compute_accuracy(mnist.test.images[:1000],mnist.test.labels[:1000]))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "time_end = time.time()\n",
    "print('使用的时间：',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa\n",
      "['/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/163_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/123_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/386_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/229_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/157_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/161_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/155_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/205_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/7_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/28_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/220_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/127_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/336_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/328_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/141_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/330_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/236_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/67_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/381_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/30_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/146_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/210_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/393_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/13_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/380_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/305_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/398_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/373_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/114_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/75_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/154_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/158_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/283_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/44_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/116_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/387_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/5_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/59_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/193_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/34_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/382_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/331_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/295_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/63_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/256_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/341_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/42_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/66_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/64_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/55_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/175_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/323_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/252_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/239_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/135_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/21_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/170_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/92_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/129_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/216_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/192_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/19_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/304_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/282_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/96_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/206_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/103_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/112_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/377_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/225_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/298_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/65_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/208_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/248_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/24_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/148_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/133_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/247_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/313_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/290_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/182_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/156_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/144_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/179_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/299_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/152_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/237_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/132_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/40_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/370_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/375_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/222_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/86_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/100_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/209_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/350_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/167_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/111_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/294_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/251_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/197_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/147_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/306_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/358_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/39_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/61_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/113_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/16_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/201_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/279_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/366_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/145_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/238_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/128_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/69_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/302_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/235_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/309_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/178_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/315_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/53_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/277_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/395_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/107_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/60_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/372_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/289_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/186_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/194_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/185_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/317_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/77_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/173_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/307_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/3_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/199_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/176_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/73_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/76_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/43_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/274_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/218_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/33_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/15_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/266_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/337_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/311_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/120_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/212_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/1_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/20_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/57_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/360_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/318_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/62_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/254_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/363_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/198_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/275_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/293_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/58_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/101_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/171_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/99_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/303_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/121_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/376_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/172_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/105_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/339_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/396_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/124_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/379_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/108_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/226_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/118_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/291_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/164_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/242_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/122_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/257_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/211_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/316_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/333_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/93_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/85_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/26_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/72_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/189_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/224_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/168_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/184_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/228_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/399_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/371_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/125_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/324_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/384_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/23_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/8_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/368_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/269_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/9_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/45_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/191_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/48_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/38_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/240_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/312_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/349_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/308_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/137_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/2_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/80_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/297_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/136_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/110_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/346_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/385_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/249_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/243_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/338_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/106_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/354_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/234_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/51_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/37_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/397_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/181_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/392_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/345_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/188_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/126_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/131_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/98_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/169_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/319_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/150_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/29_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/25_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/374_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/140_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/174_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/221_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/54_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/288_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/71_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/388_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/334_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/314_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/284_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/263_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/232_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/267_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/383_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/258_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/78_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/378_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/351_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/56_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/223_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/245_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/84_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/162_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/90_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/151_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/138_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/31_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/10_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/79_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/273_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/335_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/364_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/259_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/22_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/241_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/143_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/390_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/183_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/281_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/356_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/343_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/261_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/262_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/0_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/255_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/264_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/327_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/177_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/52_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/300_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/88_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/391_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/95_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/332_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/18_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/348_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/352_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/204_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/134_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/159_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/50_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/325_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/115_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/340_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/268_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/117_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/102_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/130_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/82_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/187_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/215_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/278_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/361_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/280_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/214_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/292_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/49_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/47_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/27_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/389_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/153_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/369_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/32_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/94_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/149_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/301_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/4_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/12_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/353_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/87_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/272_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/367_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/213_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/41_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/11_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/119_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/180_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/286_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/322_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/70_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/357_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/195_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/14_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/355_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/97_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/233_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/321_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/36_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/285_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/83_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/165_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/207_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/253_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/35_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/365_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/329_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/326_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/276_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/217_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/200_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/142_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/68_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/287_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/359_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/296_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/6_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/250_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/310_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/342_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/246_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/89_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/320_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/260_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/230_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/270_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/362_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/166_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/139_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/81_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/231_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/17_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/190_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/196_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/227_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/160_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/202_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/109_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/74_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/347_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/219_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/394_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/271_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/244_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/long/203_label_2.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/elephant/344_label_4.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/flower/265_label_3.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/horse/46_label_0.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/91_label_1.jpg', '/home/ginchoeng/jupyternotebook/yunxing/gen_pic/bus/104_label_1.jpg']\n",
      "[2, 1, 4, 2, 1, 2, 1, 2, 0, 0, 2, 1, 4, 4, 1, 4, 2, 0, 4, 0, 1, 2, 4, 0, 4, 3, 4, 4, 1, 0, 1, 1, 3, 0, 1, 4, 0, 0, 2, 0, 4, 4, 3, 0, 3, 4, 0, 0, 0, 0, 2, 4, 3, 2, 1, 0, 2, 1, 1, 2, 2, 0, 3, 3, 1, 2, 1, 1, 4, 2, 3, 0, 2, 3, 0, 1, 1, 3, 3, 3, 2, 1, 1, 2, 3, 1, 2, 1, 0, 4, 4, 2, 1, 1, 2, 4, 2, 1, 3, 3, 2, 1, 3, 4, 0, 0, 1, 0, 2, 3, 4, 1, 2, 1, 0, 3, 2, 3, 2, 3, 0, 3, 4, 1, 0, 4, 3, 2, 2, 2, 3, 0, 2, 3, 0, 2, 2, 0, 0, 0, 3, 2, 0, 0, 3, 4, 3, 1, 2, 0, 0, 0, 4, 3, 0, 3, 4, 2, 3, 3, 0, 1, 2, 1, 3, 1, 4, 2, 1, 4, 4, 1, 4, 1, 2, 1, 3, 2, 3, 1, 3, 2, 3, 4, 1, 1, 0, 0, 2, 2, 2, 2, 2, 4, 4, 1, 4, 4, 0, 0, 4, 3, 0, 0, 2, 0, 0, 3, 3, 4, 3, 1, 0, 1, 3, 1, 1, 4, 4, 3, 3, 4, 1, 4, 2, 0, 0, 4, 2, 4, 4, 2, 1, 1, 1, 2, 3, 1, 0, 0, 4, 1, 2, 2, 0, 3, 0, 4, 4, 3, 3, 3, 2, 3, 4, 3, 0, 4, 4, 0, 2, 3, 1, 2, 1, 1, 1, 0, 0, 0, 3, 4, 4, 3, 0, 3, 1, 4, 2, 3, 4, 4, 3, 3, 0, 3, 3, 4, 2, 0, 3, 1, 4, 1, 4, 0, 4, 4, 2, 1, 1, 0, 4, 1, 4, 3, 1, 1, 1, 1, 2, 2, 3, 4, 3, 2, 3, 0, 0, 0, 4, 1, 4, 0, 1, 1, 3, 0, 0, 4, 1, 3, 4, 2, 0, 0, 1, 2, 3, 4, 0, 4, 2, 0, 4, 1, 2, 4, 0, 3, 1, 2, 2, 3, 0, 4, 4, 4, 3, 2, 2, 1, 0, 3, 4, 3, 0, 3, 3, 4, 3, 1, 4, 3, 2, 3, 4, 2, 1, 1, 2, 0, 2, 2, 2, 2, 2, 1, 0, 4, 2, 4, 3, 3, 2, 4, 3, 0, 1, 1]\n",
      "bb\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "program is running 7\n",
      "使用的时间： 3.612292766571045 s\n"
     ]
    }
   ],
   "source": [
    "#导入各种库\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "#######################生成图片的路径和标签的list\n",
    "train_dir = '/home/ginchoeng/jupyternotebook/yunxing/gen_pic'\n",
    "\n",
    "horse = []\n",
    "label_horse = []\n",
    "\n",
    "bus = []\n",
    "label_bus = []\n",
    "\n",
    "long = []\n",
    "label_long = []\n",
    "\n",
    "flower = []\n",
    "label_flower = []\n",
    "\n",
    "elephant = []\n",
    "label_elephant = []\n",
    "\n",
    "\n",
    "########################第一步：获取路径下的所有图片的路径名，存放到对应的列表当中，同时贴上标签，存放到label列表当中\n",
    "def get_files(file_dir):\n",
    "    for file in os.listdir(file_dir+'/horse'):\n",
    "        horse.append(file_dir+'/horse'+'/'+file)\n",
    "        label_horse.append(0)\n",
    "        \n",
    "    for file in os.listdir(file_dir+'/bus'):\n",
    "        bus.append(file_dir+'/bus'+'/'+file)\n",
    "        label_bus.append(1)\n",
    "        \n",
    "    for file in os.listdir(file_dir+'/long'):\n",
    "        long.append(file_dir+'/long'+'/'+file)\n",
    "        label_long.append(2)\n",
    "        \n",
    "    for file in os.listdir(file_dir+'/flower'):\n",
    "        flower.append(file_dir+'/flower'+'/'+file)\n",
    "        label_flower.append(3)\n",
    "        \n",
    "    for file in os.listdir(file_dir+'/elephant'):\n",
    "        elephant.append(file_dir+'/elephant'+'/'+file)\n",
    "        label_elephant.append(4)\n",
    "        \n",
    "    \n",
    "    ############第二步:对生成的图片路径和标签list做打乱处理，把样本组合起来形成一个list(image和label)\n",
    "    image_list = np.hstack((horse,bus,long,flower,elephant))\n",
    "    label_list = np.hstack((label_horse,label_bus,label_long,label_flower,label_elephant))\n",
    "    ###利用shuffle打乱顺序\n",
    "    temp = np.array([image_list,label_list])\n",
    "    temp = temp.transpose()\n",
    "    np.random.shuffle(temp)\n",
    "    ###将所有的img和label转换成list\n",
    "    tra_images = list(temp[:,0])\n",
    "    tra_labels = list(temp[:,1])\n",
    "#     ###将所得的list分为两部分，一部分用来训练tra，一部分用来测试val\n",
    "#     ###ratio是测试集的比例\n",
    "#     n_sample = len(all_label_list)\n",
    "#     n_val = int(math.ceil(n_sample*ratio)) #测试样本数\n",
    "#     n_train = n_sample-n_val   #训练样本数\n",
    "    \n",
    "    \n",
    "#     tra_images = all_image_list\n",
    "#     tra_labels = all_label_list\n",
    "    tra_labels = [int(float(i)) for i in tra_labels]\n",
    "#     val_images = all_image_list[n_train:-1]\n",
    "#     val_labels = all_label_list[n_train:-1]\n",
    "#     val_labels = [int(float(i)) for i in val_labels]\n",
    "    \n",
    "    \n",
    "    return tra_images,tra_labels\n",
    "\n",
    "#定义精准度函数\n",
    "def compute_accuracy(v_xs,v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction,feed_dict={xs:v_xs,keep_prob:1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1),tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    result = sess.run(accuracy,feed_dict={xs:v_xs,ys:v_ys,keep_prob:1})\n",
    "    return result\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1) # shape表示生成张量的维度 stddev是标准差\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#定义卷积神经网络层了\n",
    "def conv2d(x,W):   # x代表输入的值，或者是图片的值。 W就是weight\n",
    "    #strides=[1,x轴移动距离，y轴移动距离，1]\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')#padding就是选择是否使用填充的扫描方式\n",
    "    #这里就是返回tensorflow中2维的卷积神经网络。 \n",
    "    \n",
    "    #第三个参数就是设置步长，在tensorflow中它是一个长度为4的列表。在这个列表中第一个以及最后一个元素都是必须等于1的。列表中间的两个\n",
    "    #参数分别是代表在x轴，y轴上移动的距离\n",
    "    \n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    #使用最大池化的方法， ksize=[1,height,width,1]这个是池化窗口的大小\n",
    "\n",
    "#设置placeholder来进行数据的传输\n",
    "xs = tf.placeholder(tf.float32,[None,64*64*3])\n",
    "ys = tf.placeholder(tf.float32,[None,5])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs,[-1,64,64,3]) #在定义卷积层之前，先要定义一下我们的输入。就是图片的输入\n",
    "                                      #-1表示不规定样本数量的多少，28×28是代表这个图片的尺寸，最后的1 是代表深度为1.\n",
    "      \n",
    "#第一层卷积层\n",
    "W_conv1 = weight_variable([5,5,3,32]) # 5*5就是patch的大小(就是卷积核的大小),1是代表输入通道数(如果是彩色图像就是3),32是代表有32个神经元就是有32个卷积核去关注32个特征 \n",
    "b_conv1 = bias_variable([32]) #有32个权值，那么所以就对应有32个偏置。\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1) #这一行就是卷积行    输出的大小是28*28*32,因为使用的padding是same，所以长宽不变\n",
    "h_pool1 = max_pool_2x2(h_conv1) #这一行的输出就是这一层卷积池化之后得到的结果   输出的大小是14*14*32,因为扫描的间距是2，所以缩小了一半\n",
    "\n",
    "#第二层卷积层\n",
    "W_conv2 = weight_variable([5,5,32,64]) #32是上一层的输出通道数，变成下一层的输入通道数。然后用64个卷积核去patch\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2) #输出的大小14*14*64\n",
    "h_pool2 = max_pool_2x2(h_conv2)                          #输出的大小7*7*64\n",
    "\n",
    "#全链接层1\n",
    "W_fc1 = weight_variable([16*16*64,1024]) #输入就是上一层的输出，使用包含1024个神经元的一层来处理整个图片\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,16*16*64])#把第二层卷积网络出来的 三维数据转换为一维数据\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)\n",
    "\n",
    "#全链接层2\n",
    "W_fc2 = weight_variable([1024,5]) #上一层的输出就是下一层的输入，最终是判断出0-9的图片\n",
    "b_fc2 = bias_variable([5])\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)  #最后一层的分类时使用的激活函数使用softmax\n",
    "# h_fc2_drop = tf.dropout(h_fc2,keep_prob)  #输出层可以不使用dropout\n",
    "\n",
    "\n",
    "#设置代价误差函数\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction),reduction_indices=[1]))\n",
    "# tf.summary.scalar('loss',cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)#不采用梯度下降的原因是：庞大的系统应该使用更好的优化器\n",
    "\n",
    "#全局变量的初始化\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('aa')\n",
    "    batch_xs,batch_ys = get_files(train_dir)\n",
    "    print(batch_xs)\n",
    "    print(batch_ys)\n",
    "    print('bb')\n",
    "    for i in range(400):\n",
    "        \n",
    "        #sess.run(train_step,feed_dict={xs:batch_xs,ys:batch_ys,keep_prob:0.5})\n",
    "        if i % 2 == 0:\n",
    "            print('program is running 7')\n",
    "    #         print(compute_accuracy(mnist.test.images[:1000],mnist.test.labels[:1000]))\n",
    "\n",
    "\n",
    "time_end = time.time()\n",
    "print('使用的时间：',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-bbc2e6b37e13>:12: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ginchoeng/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ginchoeng/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ginchoeng/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ginchoeng/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ginchoeng/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "0.11\n",
      "0.665\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from PIL import Image\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data  #导入数据\n",
    "#下面这一行跟分类器中的是一样的\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "def compute_accuracy(v_xs,v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction,feed_dict={xs:v_xs,keep_prob:1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1),tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    result = sess.run(accuracy,feed_dict={xs:v_xs,ys:v_ys,keep_prob:1})\n",
    "    return result\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1) # shape表示生成张量的维度 stddev是标准差\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#定义卷积神经网络层了\n",
    "def conv2d(x,W):   # x代表输入的值，或者是图片的值。 W就是weight\n",
    "    #strides=[1,x轴移动距离，y轴移动距离，1]\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')#padding就是选择是否使用填充的扫描方式\n",
    "    #这里就是返回tensorflow中2维的卷积神经网络。 \n",
    "    \n",
    "    #第三个参数就是设置步长，在tensorflow中它是一个长度为4的列表。在这个列表中第一个以及最后一个元素都是必须等于1的。列表中间的两个\n",
    "    #参数分别是代表在x轴，y轴上移动的距离\n",
    "    \n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    #使用最大池化的方法， ksize=[1,height,width,1]这个是池化窗口的大小\n",
    "\n",
    "#设置placeholder来进行数据的传输\n",
    "xs = tf.placeholder(tf.float32,[None,784])\n",
    "ys = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs,[-1,28,28,1]) #在定义卷积层之前，先要定义一下我们的输入。就是图片的输入\n",
    "                                      #-1表示不规定样本数量的多少，28×28是代表这个图片的尺寸，最后的1 是代表深度为1.\n",
    "      \n",
    "#第一层卷积层\n",
    "W_conv1 = weight_variable([5,5,1,32]) # 5*5就是patch的大小(就是卷积核的大小),1是代表输入通道数(如果是彩色图像就是3),32是代表有32个神经元就是有32个卷积核去关注32个特征 \n",
    "b_conv1 = bias_variable([32]) #有32个权值，那么所以就对应有32个偏置。\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1) #这一行就是卷积行    输出的大小是28*28*32,因为使用的padding是same，所以长宽不变\n",
    "h_pool1 = max_pool_2x2(h_conv1) #这一行的输出就是这一层卷积池化之后得到的结果   输出的大小是14*14*32,因为扫描的间距是2，所以缩小了一半\n",
    "\n",
    "#第二层卷积层\n",
    "W_conv2 = weight_variable([5,5,32,64]) #32是上一层的输出通道数，变成下一层的输入通道数。然后用64个卷积核去patch\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2) #输出的大小14*14*64\n",
    "h_pool2 = max_pool_2x2(h_conv2)                          #输出的大小7*7*64\n",
    "\n",
    "#全链接层1\n",
    "W_fc1 = weight_variable([7*7*64,1024]) #输入就是上一层的输出，使用包含1024个神经元的一层来处理整个图片\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])#把第二层卷积网络出来的 三维数据转换为一维数据\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)\n",
    "\n",
    "#全链接层2\n",
    "W_fc2 = weight_variable([1024,10]) #上一层的输出就是下一层的输入，最终是判断出0-9的图片\n",
    "b_fc2 = bias_variable([10])\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)  #最后一层的分类时使用的激活函数使用softmax\n",
    "# h_fc2_drop = tf.dropout(h_fc2,keep_prob)  #输出层可以不使用dropout\n",
    "\n",
    "\n",
    "#设置代价误差函数\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction),reduction_indices=[1]))\n",
    "# tf.summary.scalar('loss',cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)#不采用梯度下降的原因是：庞大的系统应该使用更好的优化器\n",
    "\n",
    "#全局变量的初始化\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs,batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step,feed_dict={xs:batch_xs,ys:batch_ys,keep_prob:0.5})\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy(mnist.test.images[:1000],mnist.test.labels[:1000]))\n",
    "\n",
    "        \n",
    "time_end = time.time()\n",
    "print('使用的时间：',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "my_list = [123,3.14,'yhr',['another','list']]\n",
    "\n",
    "pickle_file = open('/home/ginchoeng/jupyternotebook/yunxing/my_list.pkl','wb')\n",
    "pickle.dump(my_list,pickle_file)\n",
    "pickle_file.close()\n",
    "\n",
    "pickle_file = open('/home/ginchoeng/jupyternotebook/yunxing/my_list.pkl','rb')\n",
    "my_list2 = pickle.load(pickle_file)\n",
    "print(my_list2)\n",
    "pickle_file.close()\n",
    "\n",
    "\n",
    "for \n",
    "\n",
    "gen_pic+'/'+str(i)+'_label_'+str(lab)+'.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_dir = '/home/ginchoeng/jupyternotebook/yunxing/gen_pic'\n",
    "\n",
    "horse = []\n",
    "label_horse = []\n",
    "\n",
    "bus = []\n",
    "label_bus = []\n",
    "\n",
    "long = []\n",
    "label_long = []\n",
    "\n",
    "flower = []\n",
    "label_flower = []\n",
    "\n",
    "elephant = []\n",
    "label_elephant = []\n",
    "\n",
    "def get_files(file_dir):\n",
    "    for file in os.listdir(file_dir+'/horse'):\n",
    "        horse.append(file_dir+'/horse'+'/'+file)\n",
    "        label_horse.append(0)\n",
    "\n",
    "    for file in os.listdir(file_dir+'/bus'):\n",
    "        bus.append(file_dir+'/bus'+'/'+file)\n",
    "        label_bus.append(1)\n",
    "\n",
    "    for file in os.listdir(file_dir+'/long'):\n",
    "        long.append(file_dir+'/long'+'/'+file)\n",
    "        label_long.append(2)\n",
    "\n",
    "    for file in os.listdir(file_dir+'/flower'):\n",
    "        flower.append(file_dir+'/flower'+'/'+file)\n",
    "        label_flower.append(3)\n",
    "\n",
    "    for file in os.listdir(file_dir+'/elephant'):\n",
    "        elephant.append(file_dir+'/elephant'+'/'+file)\n",
    "        label_elephant.append(4)\n",
    "        \n",
    "    image_list = np.hstack((horse,bus,long,flower,elephant))\n",
    "    label_list = np.hstack((label_horse,label_bus,label_long,label_flower,label_elephant))\n",
    "    ###利用shuffle打乱顺序\n",
    "    temp = np.array([image_list,label_list])\n",
    "    temp = temp.transpose()\n",
    "    np.random.shuffle(temp)\n",
    "    ###将所有的img和label转换成list\n",
    "    all_image_list = list(temp[:,0])\n",
    "    all_label_list = list(temp[:,1])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
